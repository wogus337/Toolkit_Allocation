import os
import streamlit as st
import pandas as pd
import numpy as np
from scipy.optimize import minimize
import warnings

warnings.filterwarnings('ignore')

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="[ê¸€ë¡œë²Œìì‚°ë°°ë¶„ì „ëµìœ„ì›íšŒ] Quantitative Sleeve Allocation",
    layout="wide"
)

# í°íŠ¸ í¬ê¸° ì¡°ì • CSS
st.markdown("""
    <style>
        /* ì „ì²´ í…ìŠ¤íŠ¸ í¬ê¸° ì¡°ì • */
        html, body, [class*="css"] {
            font-size: 12px !important;
        }

        /* í—¤ë” í¬ê¸° ì¡°ì • */
        h1 {
            font-size: 1.4rem !important;
        }

        h2 {
            font-size: 1.2rem !important;
        }

        h3 {
            font-size: 1.1rem !important;
        }

        /* ë³¸ë¬¸ í…ìŠ¤íŠ¸ */
        p, div, span {
            font-size: 12px !important;
        }

        /* ë©”íŠ¸ë¦­ ì»´í¬ë„ŒíŠ¸ */
        [data-testid="stMetricValue"] {
            font-size: 1.2rem !important;
        }

        [data-testid="stMetricLabel"] {
            font-size: 0.9rem !important;
        }

        /* ë°ì´í„°í”„ë ˆì„ */
        .dataframe {
            font-size: 11px !important;
        }

        /* ì‚¬ì´ë“œë°” */
        [data-testid="stSidebar"] {
            font-size: 12px !important;
        }

        /* ë¼ë””ì˜¤ ë²„íŠ¼, ì²´í¬ë°•ìŠ¤ ë“± */
        label {
            font-size: 12px !important;
        }

        /* ì…ë ¥ í•„ë“œ */
        input, select, textarea {
            font-size: 12px !important;
        }

        /* ë²„íŠ¼ */
        button {
            font-size: 12px !important;
        }

        /* ì •ë³´/ê²½ê³  ë©”ì‹œì§€ */
        [data-baseweb="notification"] {
            font-size: 11px !important;
        }

        /* í…Œì´ë¸” ìŠ¤íƒ€ì¼ ê°œì„  */
        .dataframe {
            width: 100% !important;
            border-collapse: collapse !important;
            table-layout: fixed !important;
        }

        .dataframe th {
            background: linear-gradient(180deg, #1f2937 0%, #111827 100%) !important;
            color: #fafafa !important;
            font-weight: 600 !important;
            padding: 10px 8px !important;
            text-align: center !important;
            border: 1px solid #374151 !important;
            font-size: 11px !important;
        }

        .dataframe td {
            padding: 10px 8px !important;
            text-align: center !important;
            border: 1px solid #374151 !important;
            background-color: #1f2937 !important;
            color: #e5e7eb !important;
            font-size: 11px !important;
        }

        .dataframe tbody tr:nth-child(even) {
            background-color: #1a1f2e !important;
        }

        .dataframe tbody tr:nth-child(even) td {
            background-color: #1a1f2e !important;
        }

        .dataframe tbody tr:hover {
            background-color: #374151 !important;
        }

        .dataframe tbody tr:hover td {
            background-color: #374151 !important;
        }

        /* ì¹¼ëŸ¼ ë„ˆë¹„ ë™ì¼í•˜ê²Œ ì„¤ì • - ëª¨ë“  ì¹¼ëŸ¼ ë™ì¼í•œ ë„ˆë¹„ */
        .dataframe {
            table-layout: fixed !important;
        }

        .dataframe th,
        .dataframe td {
            width: 12.5% !important;
            word-wrap: break-word !important;
        }

        /* ì²« ë²ˆì§¸ ì¹¼ëŸ¼(SLEEVE)ê³¼ ë§ˆì§€ë§‰ ì¹¼ëŸ¼(GROUP)ë„ ë™ì¼í•œ ë„ˆë¹„ */
        .dataframe th:first-child,
        .dataframe td:first-child,
        .dataframe th:last-child,
        .dataframe td:last-child {
            width: 12.5% !important;
            text-align: left !important;
            font-weight: 500 !important;
        }

        /* ìˆ«ì ì¹¼ëŸ¼ ìš°ì¸¡ ì •ë ¬ ë° í°íŠ¸ */
        .dataframe td:nth-child(n+2):not(:last-child) {
            text-align: right !important;
            font-family: 'Courier New', monospace !important;
            font-weight: 500 !important;
        }

        .dataframe th:nth-child(n+2):not(:last-child) {
            text-align: right !important;
        }

        /* 3ì—´ ì„¤ì • ë¶€ë¶„ ì„¸ë¡œ êµ¬ë¶„ì„  */
        [data-testid="column"]:not(:last-child) {
            border-right: 2px solid #000000 !important;
            padding-right: 20px !important;
            margin-right: 0 !important;
        }

        [data-testid="column"]:not(:first-child) {
            padding-left: 20px !important;
            margin-left: 0 !important;
        }

        /* ì»¬ëŸ¼ ì»¨í…Œì´ë„ˆì— êµ¬ë¶„ì„  ì¶”ê°€ */
        div[data-testid="column"]:not(:last-child) {
            position: relative;
        }

        div[data-testid="column"]:not(:last-child)::after {
            content: "";
            position: absolute;
            right: -1px;
            top: 0;
            bottom: 0;
            width: 2px;
            background-color: #000000;
            z-index: 1;
        }
    </style>
""", unsafe_allow_html=True)

st.markdown('<h1 style="font-size: 6.0rem;">[ê¸€ë¡œë²Œìì‚°ë°°ë¶„ì „ëµìœ„ì›íšŒ] Quantitative Sleeve Allocation</h1>', unsafe_allow_html=True)

# ReadMe ì„¹ì…˜
st.markdown("""
    <div style="font-size: 12px;">
        <strong>ReadMe</strong><br>
        1. ì •í•´ì§„ ì–‘ì‹ì˜ ì—‘ì…€íŒŒì¼ì„ ì—…ë¡œë“œí•œ í›„ ìµœì í™”ë¥¼ ìˆ˜í–‰í•©ë‹ˆë‹¤. <br> 
        2. ì‚¬ì´ë“œë°”ì—ì„œ í€ë“œ(530810 or 530950)ë¥¼ ì„ íƒí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. <br> 
        3. ìµœì í™”ì˜ ê¸°ëŒ€ìˆ˜ìµë¥ ì€ ê³¼ê±°ìˆ˜ìµë¥  í™œìš©, ìœ„ì›íšŒ ìŠ¤ì½”ì–´ë§ ê²°ê³¼ ì ìš©, ëª¬í…Œì¹¼ë¡œ ì‹œë®¬ë ˆì´ì…˜ ë°©ë²•ì„ ì„ íƒí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. <br> 
        4. ìµœì í™”ëŠ” Max Sharpe, Min Risk, Risk Parity ì„¸ ê°€ì§€ë¥¼ ì ìš©í•©ë‹ˆë‹¤. <br> 
        5. ìµœì í™” ê²°ê³¼ëŠ” í…Œì´ë¸”ë¡œ ì¡°íšŒí•  ìˆ˜ ìˆê³ , CSV íŒŒì¼ë¡œ ë‹¤ìš´ë¡œë“œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. <br>
        <br>
    </div>
""", unsafe_allow_html=True)

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if 'uploaded_file' not in st.session_state:
    st.session_state.uploaded_file = None
if 'data_loaded' not in st.session_state:
    st.session_state.data_loaded = False
if 'fund_selected' not in st.session_state:
    st.session_state.fund_selected = None


def load_excel_data(uploaded_file):
    """ì—‘ì…€ íŒŒì¼ì—ì„œ ë°ì´í„° ë¡œë“œ"""
    try:
        # ê° ì‹œíŠ¸ ì½ê¸°
        price_df = pd.read_excel(uploaded_file, sheet_name='ê¸°ì¤€ê°€')
        Current_df = pd.read_excel(uploaded_file, sheet_name='Current')
        Gr_MinMax_df = pd.read_excel(uploaded_file, sheet_name='Gr_MinMax')

        return price_df, Current_df, Gr_MinMax_df
    except Exception as e:
        st.error(f"íŒŒì¼ ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        return None, None, None


def filter_data_by_fund(price_df, Current_df, Gr_MinMax_df, fund_type):
    """í€ë“œ íƒ€ì…ì— ë”°ë¼ ë°ì´í„° í•„í„°ë§"""
    if fund_type == '530810':
        # 530950 ê´€ë ¨ ì¹¼ëŸ¼ ì œê±°
        Current_filtered = Current_df.drop(columns=[col for col in Current_df.columns if '530950' in str(col)],
                                           errors='ignore')
        Gr_MinMax_filtered = Gr_MinMax_df.drop(columns=[col for col in Gr_MinMax_df.columns if '530950' in str(col)],
                                               errors='ignore')
        weight_col = 'F530810'
        min_col = 'MIN_530810'
        max_col = 'MAX_530810'
    else:  # 530950
        # 530810 ê´€ë ¨ ì¹¼ëŸ¼ ì œê±°
        Current_filtered = Current_df.drop(columns=[col for col in Current_df.columns if '530810' in str(col)],
                                           errors='ignore')
        Gr_MinMax_filtered = Gr_MinMax_df.drop(columns=[col for col in Gr_MinMax_df.columns if '530810' in str(col)],
                                               errors='ignore')
        weight_col = 'F530950'
        min_col = 'MIN_530950'
        max_col = 'MAX_530950'

    return price_df, Current_filtered, Gr_MinMax_filtered, weight_col, min_col, max_col


def calculate_historical_returns(price_df, Current_filtered, return_period, calc_period=3):
    """ê³¼ê±°ìˆ˜ìµë¥  ê³„ì‚° (return_period ê°œì›”ì˜ ê³¼ê±° ë°ì´í„°ë¥¼ ì‚¬ìš©í•˜ì—¬ 3ê°œì›” ê¸°ê°„ ìˆ˜ìµë¥ ë¡œ ë³€í™˜)"""
    # DATE ì¹¼ëŸ¼ì„ ë‚ ì§œë¡œ ë³€í™˜
    if 'DATE' in price_df.columns:
        price_df['DATE'] = pd.to_datetime(price_df['DATE'])
        price_df = price_df.sort_values('DATE')
    else:
        # DATE ì¹¼ëŸ¼ì´ ì—†ìœ¼ë©´ ì¸ë±ìŠ¤ ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬
        price_df = price_df.sort_index()

    # CODEë³„ë¡œ ìˆ˜ìµë¥  ê³„ì‚°
    returns_dict = {}
    sleeves = Current_filtered['SLEEVE'].unique()

    # í•­ìƒ 3ê°œì›” ê¸°ê°„ ìˆ˜ìµë¥ ë¡œ ê³„ì‚°
    # ìº˜ë¦°ë” ê¸°ì¤€ìœ¼ë¡œ ì •í™•íˆ calc_period ê°œì›” ì „ ë‚ ì§œë¥¼ ì°¾ì•„ì„œ ê³„ì‚°

    # DATEë¥¼ ì œì™¸í•œ ì¹¼ëŸ¼ë“¤ì´ CODE ê°’ë“¤
    code_columns = [col for col in price_df.columns if col != 'DATE']

    for sleeve in sleeves:
        sleeve_codes = Current_filtered[Current_filtered['SLEEVE'] == sleeve]['CODE'].astype(str).tolist()

        # í•´ë‹¹ sleeveì˜ CODEì™€ ë§¤ì¹­ë˜ëŠ” ì¹¼ëŸ¼ë“¤
        matched_cols = [col for col in code_columns if str(col) in sleeve_codes]

        if len(matched_cols) == 0:
            returns_dict[sleeve] = 0.0
            continue

        # ê° CODE(ì¹¼ëŸ¼)ë³„ ìˆ˜ìµë¥  ê³„ì‚° í›„ í‰ê· 
        sleeve_returns = []
        for code_col in matched_cols:
            if code_col not in price_df.columns:
                continue

            # í•´ë‹¹ ì¹¼ëŸ¼ì˜ ì‹œê³„ì—´ ë°ì´í„° (DATEì™€ í•¨ê»˜)
            if 'DATE' in price_df.columns:
                code_data = price_df[['DATE', code_col]].dropna(subset=[code_col]).copy()
            else:
                code_data = pd.DataFrame({code_col: price_df[code_col].dropna()})
                code_data['DATE'] = code_data.index

            if len(code_data) < 2:
                continue

            # return_period ê°œì›” ì „ë¶€í„° ì‹œì‘ (ìº˜ë¦°ë” ê¸°ì¤€)
            max_date = code_data['DATE'].max()
            cutoff_date = max_date - pd.DateOffset(months=return_period)
            code_data_filtered = code_data[code_data['DATE'] >= cutoff_date].copy()

            if len(code_data_filtered) < 2:
                continue

            # 3ê°œì›” ê¸°ê°„ ìˆ˜ìµë¥ ë“¤ì„ ê³„ì‚°
            # ê° ë‚ ì§œì— ëŒ€í•´ ì •í™•íˆ 3ê°œì›” ì „ ë‚ ì§œë¥¼ ì°¾ì•„ì„œ ìˆ˜ìµë¥  ê³„ì‚°
            period_returns = []
            for i in range(len(code_data_filtered)):
                current_date = code_data_filtered.iloc[i]['DATE']
                target_date = current_date - pd.DateOffset(months=calc_period)

                # target_dateì™€ ê°€ì¥ ê°€ê¹Œìš´ ë‚ ì§œ ì°¾ê¸° (target_date ì´ì „ ë˜ëŠ” ê°™ì€ ë‚ ì§œ)
                valid_dates = code_data[code_data['DATE'] <= current_date]
                if len(valid_dates) == 0:
                    continue

                date_diff = (valid_dates['DATE'] - target_date).abs()
                if len(date_diff) == 0:
                    continue

                closest_idx = date_diff.idxmin()

                if closest_idx is not None:
                    current_price = code_data_filtered.iloc[i][code_col]
                    prev_price = code_data.loc[closest_idx, code_col]

                    # ê°€ê²©ì´ 0ì´ ì•„ë‹Œ ê²½ìš°ë§Œ ê³„ì‚°
                    if current_price > 0 and prev_price > 0:
                        # 3ê°œì›” ìˆ˜ìµë¥  ê³„ì‚° (í¼ì„¼íŠ¸)
                        period_return = (current_price / prev_price - 1) * 100
                        period_returns.append(period_return)

            if period_returns:
                sleeve_returns.append(np.mean(period_returns))

        returns_dict[sleeve] = np.mean(sleeve_returns) if sleeve_returns else 0.0

    return returns_dict


def calculate_monte_carlo_returns(price_df, Current_filtered, return_period, corr_matrix, sleeves_list, calc_period=3,
                                  n_simulations=1000):
    """ëª¬í…Œì¹¼ë¡œ ì‹œë®¬ë ˆì´ì…˜ì„ í†µí•œ ê¸°ëŒ€ìˆ˜ìµë¥  ê³„ì‚° (ìƒê´€ê´€ê³„ ê³ ë ¤, 3ê°œì›” ê¸°ê°„ ìˆ˜ìµë¥ ë¡œ ì‚°ì¶œ)"""
    # ëœë¤ ì‹œë“œ ì„¤ì • (ì¬í˜„ ê°€ëŠ¥ì„±)
    np.random.seed(42)

    # DATE ì¹¼ëŸ¼ì„ ë‚ ì§œë¡œ ë³€í™˜
    if 'DATE' in price_df.columns:
        price_df['DATE'] = pd.to_datetime(price_df['DATE'])
        price_df = price_df.sort_values('DATE')
    else:
        # DATE ì¹¼ëŸ¼ì´ ì—†ìœ¼ë©´ ì¸ë±ìŠ¤ ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬
        price_df = price_df.sort_index()

    # í•­ìƒ 3ê°œì›” ê¸°ê°„ ìˆ˜ìµë¥ ë¡œ ê³„ì‚°
    # ìº˜ë¦°ë” ê¸°ì¤€ìœ¼ë¡œ ì •í™•íˆ calc_period ê°œì›” ì „ ë‚ ì§œë¥¼ ì°¾ì•„ì„œ ê³„ì‚°

    # DATEë¥¼ ì œì™¸í•œ ì¹¼ëŸ¼ë“¤ì´ CODE ê°’ë“¤
    code_columns = [col for col in price_df.columns if col != 'DATE']

    # ê° sleeveë³„ ìˆ˜ìµë¥  ì‹œê³„ì—´ ê³„ì‚°
    sleeve_returns_series = {}

    for sleeve in sleeves_list:
        sleeve_codes = Current_filtered[Current_filtered['SLEEVE'] == sleeve]['CODE'].astype(str).tolist()

        # í•´ë‹¹ sleeveì˜ CODEì™€ ë§¤ì¹­ë˜ëŠ” ì¹¼ëŸ¼ë“¤
        matched_cols = [col for col in code_columns if str(col) in sleeve_codes]

        if len(matched_cols) == 0:
            sleeve_returns_series[sleeve] = []
            continue

        # ê° CODE(ì¹¼ëŸ¼)ë³„ 3ê°œì›” ìˆ˜ìµë¥  ê³„ì‚°
        all_returns = []
        for code_col in matched_cols:
            if code_col not in price_df.columns:
                continue

            # í•´ë‹¹ ì¹¼ëŸ¼ì˜ ì‹œê³„ì—´ ë°ì´í„° (DATEì™€ í•¨ê»˜)
            if 'DATE' in price_df.columns:
                code_data = price_df[['DATE', code_col]].dropna(subset=[code_col]).copy()
            else:
                code_data = pd.DataFrame({code_col: price_df[code_col].dropna()})
                code_data['DATE'] = code_data.index

            if len(code_data) < 2:
                continue

            # return_period ê°œì›” ì „ë¶€í„° ì‹œì‘ (ìº˜ë¦°ë” ê¸°ì¤€)
            max_date = code_data['DATE'].max()
            cutoff_date = max_date - pd.DateOffset(months=return_period)
            code_data_filtered = code_data[code_data['DATE'] >= cutoff_date].copy()

            if len(code_data_filtered) < 2:
                continue

            # 3ê°œì›” ê¸°ê°„ ìˆ˜ìµë¥ ë“¤ì„ ê³„ì‚°
            # ê° ë‚ ì§œì— ëŒ€í•´ ì •í™•íˆ 3ê°œì›” ì „ ë‚ ì§œë¥¼ ì°¾ì•„ì„œ ìˆ˜ìµë¥  ê³„ì‚°
            for i in range(len(code_data_filtered)):
                current_date = code_data_filtered.iloc[i]['DATE']
                target_date = current_date - pd.DateOffset(months=calc_period)

                # target_dateì™€ ê°€ì¥ ê°€ê¹Œìš´ ë‚ ì§œ ì°¾ê¸°
                date_diff = (code_data['DATE'] - target_date).abs()
                closest_idx = date_diff.idxmin()

                if closest_idx is not None and code_data.loc[closest_idx, 'DATE'] <= current_date:
                    current_price = code_data_filtered.iloc[i][code_col]
                    prev_price = code_data.loc[closest_idx, code_col]

                    if current_price > 0 and prev_price > 0:
                        # 3ê°œì›” ìˆ˜ìµë¥  ê³„ì‚° (í¼ì„¼íŠ¸)
                        period_return = (current_price / prev_price - 1) * 100
                        all_returns.append(period_return)

        sleeve_returns_series[sleeve] = all_returns

    # ê³µí†µ ê¸°ê°„ ì°¾ê¸° (ìµœì†Œ ê¸¸ì´ë¡œ ë§ì¶¤)
    min_len = min([len(returns) for returns in sleeve_returns_series.values() if len(returns) > 0], default=0)
    if min_len == 0:
        # ê³µí†µ ê¸°ê°„ì´ ì—†ìœ¼ë©´ ê° sleeveë³„ í‰ê·  ì‚¬ìš©
        returns_dict = {sleeve: np.mean(returns) if returns else 0.0
                        for sleeve, returns in sleeve_returns_series.items()}
        return returns_dict

    # ê³µí†µ ê¸°ê°„ì˜ ìˆ˜ìµë¥  í–‰ë ¬ êµ¬ì„±
    n_sleeves = len(sleeves_list)
    returns_matrix = np.zeros((min_len, n_sleeves))

    for i, sleeve in enumerate(sleeves_list):
        returns = sleeve_returns_series.get(sleeve, [])
        if len(returns) >= min_len:
            returns_matrix[:, i] = returns[:min_len]
        else:
            # ë°ì´í„°ê°€ ë¶€ì¡±í•˜ë©´ í‰ê· ìœ¼ë¡œ ì±„ì›€
            returns_matrix[:, i] = np.mean(returns) if returns else 0.0

    # í‰ê·  ìˆ˜ìµë¥  ë²¡í„° (3ê°œì›” ê¸°ê°„ ìˆ˜ìµë¥ )
    mean_returns = np.mean(returns_matrix, axis=0)

    # ê³µë¶„ì‚° í–‰ë ¬ ê³„ì‚° (3ê°œì›” ê¸°ê°„ ë³€ë™ì„±)
    cov_matrix = np.cov(returns_matrix.T)

    # ìƒê´€ê´€ê³„ í–‰ë ¬ê³¼ ì¼ì¹˜í•˜ë„ë¡ ì¡°ì •
    std_returns = np.std(returns_matrix, axis=0)
    for i in range(n_sleeves):
        for j in range(n_sleeves):
            if std_returns[i] > 0 and std_returns[j] > 0:
                cov_matrix[i, j] = corr_matrix[i, j] * std_returns[i] * std_returns[j]

    # ëª¬í…Œì¹¼ë¡œ ì‹œë®¬ë ˆì´ì…˜: ë‹¤ë³€ëŸ‰ ì •ê·œë¶„í¬
    try:
        simulated_returns = np.random.multivariate_normal(mean_returns, cov_matrix, n_simulations)
        returns_dict = {sleeves_list[i]: np.mean(simulated_returns[:, i]) for i in range(n_sleeves)}
    except:
        # ê³µë¶„ì‚° í–‰ë ¬ì´ ì–‘ì •ë¶€í˜¸ê°€ ì•„ë‹Œ ê²½ìš°, ê° sleeveë³„ ë…ë¦½ì ìœ¼ë¡œ ì‹œë®¬ë ˆì´ì…˜
        returns_dict = {}
        for i, sleeve in enumerate(sleeves_list):
            returns = sleeve_returns_series.get(sleeve, [])
            if returns:
                mean_return = np.mean(returns)
                std_return = np.std(returns)
                simulated_returns = np.random.normal(mean_return, std_return, n_simulations)
                returns_dict[sleeve] = np.mean(simulated_returns)
            else:
                returns_dict[sleeve] = 0.0

    return returns_dict


def calculate_volatility(price_df, Current_filtered, vol_period, calc_period=3):
    """ë³€ë™ì„± ê³„ì‚° (vol_period ê°œì›”ì˜ ê³¼ê±° ë°ì´í„°ë¥¼ ì‚¬ìš©í•˜ì—¬ 3ê°œì›” ê¸°ê°„ ë³€ë™ì„±ìœ¼ë¡œ ë³€í™˜)"""
    # DATE ì¹¼ëŸ¼ì„ ë‚ ì§œë¡œ ë³€í™˜
    if 'DATE' in price_df.columns:
        price_df['DATE'] = pd.to_datetime(price_df['DATE'])
        price_df = price_df.sort_values('DATE')
    else:
        # DATE ì¹¼ëŸ¼ì´ ì—†ìœ¼ë©´ ì¸ë±ìŠ¤ ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬
        price_df = price_df.sort_index()

    volatility_dict = {}
    sleeves = Current_filtered['SLEEVE'].unique()

    # í•­ìƒ 3ê°œì›” ê¸°ê°„ ë³€ë™ì„±ìœ¼ë¡œ ê³„ì‚°
    # ìº˜ë¦°ë” ê¸°ì¤€ìœ¼ë¡œ ì •í™•íˆ calc_period ê°œì›” ì „ ë‚ ì§œë¥¼ ì°¾ì•„ì„œ ê³„ì‚°

    # DATEë¥¼ ì œì™¸í•œ ì¹¼ëŸ¼ë“¤ì´ CODE ê°’ë“¤
    code_columns = [col for col in price_df.columns if col != 'DATE']

    for sleeve in sleeves:
        sleeve_codes = Current_filtered[Current_filtered['SLEEVE'] == sleeve]['CODE'].astype(str).tolist()

        # í•´ë‹¹ sleeveì˜ CODEì™€ ë§¤ì¹­ë˜ëŠ” ì¹¼ëŸ¼ë“¤
        matched_cols = [col for col in code_columns if str(col) in sleeve_codes]

        if len(matched_cols) == 0:
            volatility_dict[sleeve] = 0.0
            continue

        # ê° CODE(ì¹¼ëŸ¼)ë³„ ë³€ë™ì„± ê³„ì‚° í›„ í‰ê· 
        sleeve_vols = []
        for code_col in matched_cols:
            if code_col not in price_df.columns:
                continue

            # í•´ë‹¹ ì¹¼ëŸ¼ì˜ ì‹œê³„ì—´ ë°ì´í„° (DATEì™€ í•¨ê»˜)
            if 'DATE' in price_df.columns:
                code_data = price_df[['DATE', code_col]].dropna(subset=[code_col]).copy()
            else:
                code_data = pd.DataFrame({code_col: price_df[code_col].dropna()})
                code_data['DATE'] = code_data.index

            if len(code_data) < 2:
                continue

            # vol_period ê°œì›” ì „ë¶€í„° ì‹œì‘ (ìº˜ë¦°ë” ê¸°ì¤€)
            max_date = code_data['DATE'].max()
            cutoff_date = max_date - pd.DateOffset(months=vol_period)
            code_data_filtered = code_data[code_data['DATE'] >= cutoff_date].copy()

            if len(code_data_filtered) < 2:
                continue

            # 3ê°œì›” ê¸°ê°„ ìˆ˜ìµë¥ ë“¤ì„ ê³„ì‚°
            # ê° ë‚ ì§œì— ëŒ€í•´ ì •í™•íˆ 3ê°œì›” ì „ ë‚ ì§œë¥¼ ì°¾ì•„ì„œ ìˆ˜ìµë¥  ê³„ì‚°
            period_returns = []
            for i in range(len(code_data_filtered)):
                current_date = code_data_filtered.iloc[i]['DATE']
                target_date = current_date - pd.DateOffset(months=calc_period)

                # target_dateì™€ ê°€ì¥ ê°€ê¹Œìš´ ë‚ ì§œ ì°¾ê¸°
                date_diff = (code_data['DATE'] - target_date).abs()
                closest_idx = date_diff.idxmin()

                if closest_idx is not None and code_data.loc[closest_idx, 'DATE'] <= current_date:
                    current_price = code_data_filtered.iloc[i][code_col]
                    prev_price = code_data.loc[closest_idx, code_col]

                    if current_price > 0 and prev_price > 0:
                        # 3ê°œì›” ìˆ˜ìµë¥  ê³„ì‚° (í¼ì„¼íŠ¸)
                        period_return = (current_price / prev_price - 1) * 100
                        period_returns.append(period_return)

            if len(period_returns) > 1:
                # 3ê°œì›” ê¸°ê°„ ìˆ˜ìµë¥ ì˜ ë³€ë™ì„± (í¼ì„¼íŠ¸, ì—°ìœ¨í™”í•˜ì§€ ì•ŠìŒ)
                vol = np.std(period_returns)
                sleeve_vols.append(vol)

        volatility_dict[sleeve] = np.mean(sleeve_vols) if sleeve_vols else 0.0

    return volatility_dict


def calculate_correlation_matrix(price_df, Current_filtered, sleeves):
    """Sleeve ê°„ ìƒê´€ê´€ê³„ í–‰ë ¬ ê³„ì‚°"""
    if 'DATE' in price_df.columns:
        price_df['DATE'] = pd.to_datetime(price_df['DATE'])
        price_df = price_df.sort_values('DATE')
    else:
        # DATE ì¹¼ëŸ¼ì´ ì—†ìœ¼ë©´ ì¸ë±ìŠ¤ ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬
        price_df = price_df.sort_index()

    # DATEë¥¼ ì œì™¸í•œ ì¹¼ëŸ¼ë“¤ì´ CODE ê°’ë“¤
    code_columns = [col for col in price_df.columns if col != 'DATE']

    # ê° sleeveë³„ ìˆ˜ìµë¥  ì‹œê³„ì—´ ê³„ì‚°
    sleeve_returns = {}

    for sleeve in sleeves:
        sleeve_codes = Current_filtered[Current_filtered['SLEEVE'] == sleeve]['CODE'].astype(str).tolist()

        # í•´ë‹¹ sleeveì˜ CODEì™€ ë§¤ì¹­ë˜ëŠ” ì¹¼ëŸ¼ë“¤
        matched_cols = [col for col in code_columns if str(col) in sleeve_codes]

        daily_returns = []
        for code_col in matched_cols:
            if code_col not in price_df.columns:
                continue

            # í•´ë‹¹ ì¹¼ëŸ¼ì˜ ì‹œê³„ì—´ ë°ì´í„° (DATEì™€ í•¨ê»˜)
            if 'DATE' in price_df.columns:
                code_data = price_df[['DATE', code_col]].dropna(subset=[code_col]).copy()
            else:
                code_data = pd.DataFrame({code_col: price_df[code_col].dropna()})
                code_data['DATE'] = code_data.index

            if len(code_data) < 2:
                continue

            # ì¼ë³„ ìˆ˜ìµë¥  ê³„ì‚°
            for i in range(1, len(code_data)):
                latest_price = code_data.iloc[i][code_col]
                prev_price = code_data.iloc[i - 1][code_col]

                if latest_price > 0 and prev_price > 0:
                    period_return = (latest_price / prev_price - 1) * 100
                    daily_returns.append(period_return)

        if daily_returns:
            # ìµœê·¼ 1ë…„ì¹˜ ë°ì´í„° ì‚¬ìš© (ì•½ 252 ì˜ì—…ì¼, ìµœëŒ€ 365ì¼)
            sleeve_returns[sleeve] = daily_returns[-365:] if len(daily_returns) > 365 else daily_returns

    # ìƒê´€ê´€ê³„ í–‰ë ¬ ê³„ì‚°
    n_sleeves = len(sleeves)
    corr_matrix = np.eye(n_sleeves)

    for i, sleeve1 in enumerate(sleeves):
        for j, sleeve2 in enumerate(sleeves):
            if i != j and sleeve1 in sleeve_returns and sleeve2 in sleeve_returns:
                returns1 = sleeve_returns[sleeve1]
                returns2 = sleeve_returns[sleeve2]
                min_len = min(len(returns1), len(returns2))
                if min_len > 1:
                    corr = np.corrcoef(returns1[:min_len], returns2[:min_len])[0, 1]
                    if not np.isnan(corr):
                        corr_matrix[i, j] = corr

    return corr_matrix


def optimize_portfolio(Current_filtered, Gr_MinMax_filtered, expected_returns, volatilities,
                       corr_matrix, weight_col, min_col, max_col, objective, risk_free_rate,
                       dur_buffer, portfolio_duration, return_period):
    """í¬íŠ¸í´ë¦¬ì˜¤ ìµœì í™”"""
    sleeves = Current_filtered['SLEEVE'].unique().tolist()
    n = len(sleeves)

    # í˜„ì¬ ë¹„ì¤‘
    current_weights = Current_filtered.set_index('SLEEVE')[weight_col].to_dict()
    current_weights_array = np.array([current_weights.get(s, 0) for s in sleeves])
    current_weights_normalized = current_weights_array / current_weights_array.sum()

    # ê¸°ëŒ€ìˆ˜ìµë¥  ë²¡í„°
    mu = np.array([expected_returns.get(s, 0) for s in sleeves]) / 100  # í¼ì„¼íŠ¸ë¥¼ ì†Œìˆ˜ë¡œ ë³€í™˜

    # ë³€ë™ì„± ë²¡í„°
    sigma = np.array([volatilities.get(s, 0) for s in sleeves]) / 100  # í¼ì„¼íŠ¸ë¥¼ ì†Œìˆ˜ë¡œ ë³€í™˜

    # ë³€ë™ì„±ì´ ëª¨ë‘ 0ì¸ ê²½ìš° ì²˜ë¦¬
    if np.all(sigma == 0):
        st.warning("âš ï¸ ëª¨ë“  Sleeveì˜ ë³€ë™ì„±ì´ 0ì…ë‹ˆë‹¤. ìµœì†Œ ë³€ë™ì„±ì„ 0.01%ë¡œ ì„¤ì •í•©ë‹ˆë‹¤.")
        sigma = np.where(sigma == 0, 0.0001, sigma)  # 0.01% = 0.0001

    # ê³µë¶„ì‚° í–‰ë ¬
    cov_matrix = np.outer(sigma, sigma) * corr_matrix

    # ê³µë¶„ì‚° í–‰ë ¬ì´ ëª¨ë‘ 0ì¸ ê²½ìš° ì²˜ë¦¬
    if np.all(cov_matrix == 0):
        st.warning("âš ï¸ ê³µë¶„ì‚° í–‰ë ¬ì´ 0ì…ë‹ˆë‹¤. ëŒ€ê° í–‰ë ¬ë¡œ ëŒ€ì²´í•©ë‹ˆë‹¤.")
        cov_matrix = np.diag(sigma ** 2)

    # ì œì•½ì¡°ê±´ ì„¤ì •
    # 1. ê°œë³„ SLEEVEë³„ ë¹„ì¤‘ ì œì•½
    # ì—‘ì…€ì˜ % í˜•ì‹ ë°ì´í„°ëŠ” ì´ë¯¸ ì†Œìˆ˜ë¡œ ì½íˆë¯€ë¡œ / 100 ë¶ˆí•„ìš”
    min_weights = Current_filtered.set_index('SLEEVE')[min_col].to_dict()
    max_weights = Current_filtered.set_index('SLEEVE')[max_col].to_dict()
    bounds = [(min_weights.get(s, 0), max_weights.get(s, 1.0)) for s in sleeves]

    # 2. DUR ì œì•½
    dur_values = Current_filtered.set_index('SLEEVE')['DUR'].to_dict()
    dur_array = np.array([dur_values.get(s, 0) for s in sleeves])

    dur_min = portfolio_duration * (1 - dur_buffer / 100)
    dur_max = portfolio_duration * (1 + dur_buffer / 100)

    # 3. ê·¸ë£¹ë³„ ë¹„ì¤‘ ì œì•½
    # ì—‘ì…€ì˜ % í˜•ì‹ ë°ì´í„°ëŠ” ì´ë¯¸ ì†Œìˆ˜ë¡œ ì½íˆë¯€ë¡œ / 100 ë¶ˆí•„ìš”
    group_constraints = {}
    for _, row in Gr_MinMax_filtered.iterrows():
        group = row['GROUP']
        group_min = row.get('MIN_' + weight_col.replace('F', ''), 0)
        group_max = row.get('MAX_' + weight_col.replace('F', ''), 1.0)
        group_constraints[group] = (group_min, group_max)

    # ê·¸ë£¹ ë§¤í•‘
    group_mapping = Current_filtered.set_index('SLEEVE')['GROUP'].to_dict()

    # ëª©ì í•¨ìˆ˜ ì •ì˜
    def objective_function(w):
        w = np.array(w)
        portfolio_return = np.dot(w, mu)
        portfolio_vol = np.sqrt(np.dot(w, np.dot(cov_matrix, w)))

        if objective == "Max Sharpe":
            sharpe = (portfolio_return - risk_free_rate / 100) / portfolio_vol if portfolio_vol > 0 else -1e10
            return -sharpe  # ìµœì†Œí™”ë¥¼ ìœ„í•´ ìŒìˆ˜
        elif objective == "Min Risk":
            return portfolio_vol
        else:  # Risk Parity
            # Risk Parity: ê° ìì‚°ì˜ ê¸°ì—¬ë„ê°€ ë™ì¼í•˜ë„ë¡
            risk_contributions = w * (np.dot(cov_matrix, w) / portfolio_vol) if portfolio_vol > 0 else w
            target_risk = portfolio_vol / n
            return np.sum((risk_contributions - target_risk) ** 2)

    # ì œì•½ì¡°ê±´ í•¨ìˆ˜
    constraints = []

    # í•©ê³„ = 1 (100%ë¡œ ë³´ì •)
    constraints.append({'type': 'eq', 'fun': lambda w: np.sum(w) - 1})

    # DUR ì œì•½ (ì´ë¯¸ í•©ê³„=1ì´ë¯€ë¡œ wë¥¼ ê·¸ëŒ€ë¡œ ì‚¬ìš©)
    constraints.append({'type': 'ineq', 'fun': lambda w: np.dot(w, dur_array) - dur_min})
    constraints.append({'type': 'ineq', 'fun': lambda w: dur_max - np.dot(w, dur_array)})

    # ê·¸ë£¹ë³„ ë¹„ì¤‘ ì œì•½ (ì´ë¯¸ í•©ê³„=1ì´ë¯€ë¡œ wë¥¼ ê·¸ëŒ€ë¡œ ì‚¬ìš©)
    for group, (group_min, group_max) in group_constraints.items():
        group_sleeves = [s for s in sleeves if group_mapping.get(s) == group]
        if group_sleeves:
            group_indices = [sleeves.index(s) for s in group_sleeves]

            # í´ë¡œì € ë¬¸ì œ í•´ê²°ì„ ìœ„í•´ í•¨ìˆ˜ ìƒì„±
            def make_group_min_constraint(idx, g_min):
                return lambda w: np.sum([w[i] for i in idx]) - g_min

            def make_group_max_constraint(idx, g_max):
                return lambda w: g_max - np.sum([w[i] for i in idx])

            constraints.append({'type': 'ineq', 'fun': make_group_min_constraint(group_indices, group_min)})
            constraints.append({'type': 'ineq', 'fun': make_group_max_constraint(group_indices, group_max)})

    # íšŒì „ìœ¨ ì œì•½ (100%) - ì´ë¯¸ í•©ê³„=1ì´ë¯€ë¡œ wë¥¼ ê·¸ëŒ€ë¡œ ì‚¬ìš©
    turnover_limit = 1.0
    constraints.append(
        {'type': 'ineq', 'fun': lambda w: turnover_limit - np.sum(np.abs(w - current_weights_normalized))})

    # ì´ˆê¸°ê°’ì´ ì œì•½ì¡°ê±´ì„ ë§Œì¡±í•˜ëŠ”ì§€ í™•ì¸í•˜ê³  ì¡°ì •
    x0 = current_weights_normalized.copy()

    # ì´ˆê¸°ê°’ì´ boundsë¥¼ ë§Œì¡±í•˜ëŠ”ì§€ í™•ì¸
    for i in range(n):
        if x0[i] < bounds[i][0]:
            x0[i] = bounds[i][0]
        elif x0[i] > bounds[i][1]:
            x0[i] = bounds[i][1]

    # í•©ê³„ë¥¼ 1ë¡œ ì •ê·œí™”
    x0 = x0 / np.sum(x0) if np.sum(x0) > 0 else x0

    # ìµœì í™” ì‹¤í–‰ (ì—¬ëŸ¬ ë°©ë²• ì‹œë„)
    optimal_weights_raw = None
    methods = ['SLSQP', 'trust-constr']

    for method in methods:
        try:
            if method == 'SLSQP':
                result = minimize(
                    objective_function,
                    x0,
                    method=method,
                    bounds=bounds,
                    constraints=constraints,
                    options={'maxiter': 2000, 'ftol': 1e-6, 'disp': False}
                )
            else:  # trust-constr
                result = minimize(
                    objective_function,
                    x0,
                    method=method,
                    bounds=bounds,
                    constraints=constraints,
                    options={'maxiter': 2000, 'gtol': 1e-6, 'disp': False}
                )

            if result.success:
                # ê²°ê³¼ê°€ ì œì•½ì¡°ê±´ì„ ë§Œì¡±í•˜ëŠ”ì§€ í™•ì¸
                w_test = result.x
                w_test = w_test / np.sum(w_test) if np.sum(w_test) > 0 else w_test

                # bounds í™•ì¸
                tol = 1e-8
                bounds_ok = all(bounds[i][0] - tol <= w_test[i] <= bounds[i][1] + tol for i in range(n))

                # DUR ì œì•½ í™•ì¸
                dur_test = np.dot(w_test, dur_array)
                dur_ok = (dur_min - tol) <= dur_test <= (dur_max + tol)

                if bounds_ok and dur_ok:
                    optimal_weights_raw = w_test
                    break
        except Exception as e:
            continue

    # ëª¨ë“  ë°©ë²•ì´ ì‹¤íŒ¨í•œ ê²½ìš°, ì œì•½ì¡°ê±´ì„ ì™„í™”í•˜ì—¬ ì¬ì‹œë„
    if optimal_weights_raw is None:
        try:
            # ì œì•½ì¡°ê±´ì„ ì™„í™” (DUR ë²„í¼ë¥¼ 10% ë” ëŠ˜ë¦¼)
            dur_min_relaxed = portfolio_duration * (1 - (dur_buffer + 10) / 100)
            dur_max_relaxed = portfolio_duration * (1 + (dur_buffer + 10) / 100)

            constraints_relaxed = []
            constraints_relaxed.append({'type': 'eq', 'fun': lambda w: np.sum(w) - 1})
            constraints_relaxed.append({'type': 'ineq', 'fun': lambda w: np.dot(w, dur_array) - dur_min_relaxed})
            constraints_relaxed.append({'type': 'ineq', 'fun': lambda w: dur_max_relaxed - np.dot(w, dur_array)})

            # ê·¸ë£¹ ì œì•½ì€ ìœ ì§€
            for group, (group_min, group_max) in group_constraints.items():
                group_sleeves = [s for s in sleeves if group_mapping.get(s) == group]
                if group_sleeves:
                    group_indices = [sleeves.index(s) for s in group_sleeves]

                    def make_group_min_constraint(idx, g_min):
                        return lambda w: np.sum([w[i] for i in idx]) - g_min

                    def make_group_max_constraint(idx, g_max):
                        return lambda w: g_max - np.sum([w[i] for i in idx])

                    constraints_relaxed.append(
                        {'type': 'ineq', 'fun': make_group_min_constraint(group_indices, group_min)})
                    constraints_relaxed.append(
                        {'type': 'ineq', 'fun': make_group_max_constraint(group_indices, group_max)})

            constraints_relaxed.append(
                {'type': 'ineq', 'fun': lambda w: turnover_limit - np.sum(np.abs(w - current_weights_normalized))})

            result = minimize(
                objective_function,
                x0,
                method='SLSQP',
                bounds=bounds,
                constraints=constraints_relaxed,
                options={'maxiter': 2000, 'ftol': 1e-6, 'disp': False}
            )

            if result.success:
                optimal_weights_raw = result.x / np.sum(result.x) if np.sum(result.x) > 0 else result.x
                st.warning("âš ï¸ DUR ì œì•½ì„ ì™„í™”í•˜ì—¬ ìµœì í™”ë¥¼ ìˆ˜í–‰í–ˆìŠµë‹ˆë‹¤.")
            else:
                st.warning("âš ï¸ ìµœì í™”ê°€ ìˆ˜ë ´í•˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. í˜„ì¬ ë¹„ì¤‘ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.")
                optimal_weights_raw = current_weights_normalized
        except Exception as e:
            st.warning(f"âš ï¸ ìµœì í™” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}. í˜„ì¬ ë¹„ì¤‘ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.")
            optimal_weights_raw = current_weights_normalized

    if optimal_weights_raw is None:
        optimal_weights_raw = current_weights_normalized

    # ìµœì í™”ëŠ” 100%ë¡œ í™˜ì‚°í•œ ë¹„ì¤‘(ì •ê·œí™”ëœ ë¹„ì¤‘)ìœ¼ë¡œ ìˆ˜í–‰ë¨
    optimal_weights_normalized = optimal_weights_raw / np.sum(optimal_weights_raw) if np.sum(
        optimal_weights_raw) > 0 else optimal_weights_raw

    # ì›ë³¸ Current ì‹œíŠ¸ì˜ ë¹„ì¤‘ í•©ê³„ ê³„ì‚° (100%ë¡œ í™˜ì‚°í•˜ê¸° ì „)
    current_weights_total = current_weights_array.sum()

    # ìµœì í™”ëœ ì •ê·œí™” ë¹„ì¤‘ì„ ì›ë³¸ ë¹„ì¤‘ í•©ê³„ì— ë§ì¶°ì„œ ë³€í™˜ (ì›ë³¸ ê¸°ì¤€ ë¹„ì¤‘)
    optimal_weights_original_scale = optimal_weights_normalized * current_weights_total

    # ê²°ê³¼ ê³„ì‚° (ì •ê·œí™”ëœ ë¹„ì¤‘ ê¸°ì¤€ìœ¼ë¡œ í¬íŠ¸í´ë¦¬ì˜¤ ì§€í‘œ ê³„ì‚°)
    portfolio_return = np.dot(optimal_weights_normalized, mu) * 100
    portfolio_vol = np.sqrt(np.dot(optimal_weights_normalized, np.dot(cov_matrix, optimal_weights_normalized))) * 100
    optimal_duration = np.dot(optimal_weights_normalized, dur_array)

    # ì›ë³¸ ê¸°ì¤€ ë¹„ì¤‘ ë³€í™” ê³„ì‚°
    weight_changes = {sleeves[i]: (optimal_weights_original_scale[i] - current_weights_array[i])
                      for i in range(n)}

    # ë°˜í™˜ê°’: ì •ê·œí™”ëœ ë¹„ì¤‘(ìµœì í™”ì— ì‚¬ìš©), ì›ë³¸ ê¸°ì¤€ ë¹„ì¤‘(ê²°ê³¼ í‘œì‹œìš©)
    optimal_weights_normalized_dict = {sleeves[i]: optimal_weights_normalized[i] for i in range(n)}
    optimal_weights_original_dict = {sleeves[i]: optimal_weights_original_scale[i] for i in range(n)}

    return optimal_weights_original_dict, optimal_weights_normalized_dict, portfolio_return, portfolio_vol, optimal_duration, weight_changes


# ì‚¬ì´ë“œë°”: íŒŒì¼ ì—…ë¡œë“œ
with st.sidebar:
    # ì´ë¯¸ì§€ í‘œì‹œ
    image_path = "images/miraeasset.png"
    try:
        st.image(image_path, use_container_width=True)
    except:
        st.warning("ì´ë¯¸ì§€ë¥¼ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

    st.header("ğŸ“ ë°ì´í„° ì—…ë¡œë“œ")
    uploaded_file = st.file_uploader("ì—‘ì…€ íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”", type=['xlsx', 'xls'])

    # ì˜ˆì œ íŒŒì¼ ë‹¤ìš´ë¡œë“œ ë§í¬
    example_file_path = "images/example.xlsx"
    if os.path.exists(example_file_path):
        with open(example_file_path, "rb") as f:
            example_file_data = f.read()
            # í…ìŠ¤íŠ¸ ë§í¬ì²˜ëŸ¼ ë³´ì´ë„ë¡ ë‹¤ìš´ë¡œë“œ ë²„íŠ¼ ìƒì„±
            st.markdown('<div style="margin-top: 10px;"></div>', unsafe_allow_html=True)
            st.download_button(
                label="ğŸ“¥ ì˜ˆì œ íŒŒì¼ ë‹¤ìš´ë¡œë“œ",
                data=example_file_data,
                file_name="example.xlsx",
                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                key="example_file_download"
            )
    else:
        st.caption("ì˜ˆì œ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

    if uploaded_file is not None:
        if st.session_state.uploaded_file != uploaded_file:
            st.session_state.uploaded_file = uploaded_file
            st.session_state.data_loaded = False

        if not st.session_state.data_loaded:
            with st.spinner("ë°ì´í„° ë¡œë”© ì¤‘..."):
                price_df, Current_df, Gr_MinMax_df = load_excel_data(uploaded_file)
                if price_df is not None:
                    st.session_state.price_df = price_df
                    st.session_state.Current_df = Current_df
                    st.session_state.Gr_MinMax_df = Gr_MinMax_df
                    st.session_state.data_loaded = True

                    # ìµœê·¼ìë£Œì¼ ê³„ì‚°
                    if 'DATE' in price_df.columns:
                        price_df_date = price_df.copy()
                        price_df_date['DATE'] = pd.to_datetime(price_df_date['DATE'], errors='coerce')
                        latest_date = price_df_date['DATE'].max()
                        if pd.isna(latest_date):
                            latest_date = pd.Timestamp.today()
                        st.session_state.latest_date = latest_date
                    else:
                        # DATE ì¹¼ëŸ¼ì´ ì—†ìœ¼ë©´ ì˜¤ëŠ˜ ë‚ ì§œ ì‚¬ìš©
                        latest_date = pd.Timestamp.today()
                        st.session_state.latest_date = latest_date

                    st.success("ë°ì´í„° ë¡œë“œ ì™„ë£Œ!")
                    st.info(f"as of: {st.session_state.latest_date.strftime('%Y-%m-%d')}")

        if st.session_state.data_loaded:
            st.header("âš™ï¸ ì„¤ì •")
            fund_type = st.radio(
                "ëŒ€ìƒ í€ë“œ ì„ íƒ",
                ['530810', '530950'],
                index=0 if st.session_state.fund_selected is None else (
                    0 if st.session_state.fund_selected == '530810' else 1)
            )
            st.session_state.fund_selected = fund_type

# ë©”ì¸ ì˜ì—­
if st.session_state.data_loaded and st.session_state.fund_selected:
    price_df = st.session_state.price_df
    Current_df = st.session_state.Current_df
    Gr_MinMax_df = st.session_state.Gr_MinMax_df
    fund_type = st.session_state.fund_selected

    # ë°ì´í„° í•„í„°ë§
    price_df, Current_filtered, Gr_MinMax_filtered, weight_col, min_col, max_col = filter_data_by_fund(
        price_df, Current_df, Gr_MinMax_df, fund_type
    )

    # ê¸°ì¤€ê°€ ì‹œíŠ¸ì˜ ì¹¼ëŸ¼ ì´ë¦„ë“¤ê³¼ Current ì‹œíŠ¸ì˜ CODE ë§¤ì¹­
    valid_codes = set(Current_filtered['CODE'].astype(str))
    # DATE ì¹¼ëŸ¼ì„ ì œì™¸í•œ ëª¨ë“  ì¹¼ëŸ¼ì´ CODE í›„ë³´
    # ê° ì¹¼ëŸ¼ ì´ë¦„ì´ CODE ê°’ê³¼ ë§¤ì¹­ë¨
    if 'DATE' in price_df.columns:
        code_columns = [col for col in price_df.columns if col != 'DATE']
    else:
        code_columns = list(price_df.columns)

    # ë§¤ì¹­ë˜ëŠ” ì¹¼ëŸ¼ë§Œ í•„í„°ë§
    matched_columns = [col for col in code_columns if str(col) in valid_codes]

    if len(matched_columns) == 0:
        st.warning(f"âš ï¸ ê¸°ì¤€ê°€ ì‹œíŠ¸ì—ì„œ Current ì‹œíŠ¸ì˜ CODEì™€ ë§¤ì¹­ë˜ëŠ” ì¹¼ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        price_filtered = pd.DataFrame()
    else:
        # DATEì™€ ë§¤ì¹­ëœ ì¹¼ëŸ¼ë“¤ë§Œ ì„ íƒ
        price_filtered = price_df[['DATE'] + matched_columns].copy() if 'DATE' in price_df.columns else price_df[
            matched_columns].copy()

    st.header("ğŸ“ˆ ìš”ì•½ ì •ë³´")

    # Sleeveë³„ ë¹„ì¤‘ í‘œì‹œ (í•˜ë‚˜ì˜ í…Œì´ë¸”ë¡œ í†µí•©)
    st.subheader("Sleeveë³„ ì •ë³´")
    weight_df = Current_filtered[['SLEEVE', weight_col, 'DUR', min_col, max_col, 'GROUP']].copy()
    total_weight = weight_df[weight_col].sum()

    # ì›ë³¸ ë¹„ì¤‘ì„ % í˜•ì‹ìœ¼ë¡œ ë³€í™˜ (0.11 -> 11.00%)
    weight_df['ì›ë³¸ ë¹„ì¤‘ (%)'] = (weight_df[weight_col] * 100).round(2).apply(lambda x: f"{x:.2f}")

    # 100% í™˜ì‚° ë¹„ì¤‘ ê³„ì‚°
    weight_df['100% í™˜ì‚° ë¹„ì¤‘ (%)'] = (weight_df[weight_col] / total_weight * 100).round(2).apply(lambda x: f"{x:.2f}")

    # MIN/MAX ë¹„ì¤‘ì„ % í˜•ì‹ìœ¼ë¡œ ë³€í™˜
    weight_df['ìµœì†Œ ë¹„ì¤‘ (%)'] = (weight_df[min_col] * 100).round(2).apply(lambda x: f"{x:.2f}")
    weight_df['ìµœëŒ€ ë¹„ì¤‘ (%)'] = (weight_df[max_col] * 100).round(2).apply(lambda x: f"{x:.2f}")

    # DUR í¬ë§·íŒ…
    weight_df['DUR'] = weight_df['DUR'].apply(lambda x: f"{x:.2f}" if pd.notna(x) else "-")

    # EXPECTED_Rì´ ìˆìœ¼ë©´ ì¶”ê°€
    if 'EXPECTED_R' in Current_filtered.columns:
        expected_r_dict = Current_filtered.groupby('SLEEVE')['EXPECTED_R'].first().to_dict()
        weight_df['ìŠ¤ì½”ì–´ë§ ê¸°ëŒ€ìˆ˜ìµë¥  (%)'] = weight_df['SLEEVE'].map(
            lambda
                x: f"{round(expected_r_dict.get(x, 0) * 100 if expected_r_dict.get(x, 0) < 1.0 else expected_r_dict.get(x, 0), 2):.2f}"
        )
        # ìµœì¢… í…Œì´ë¸” (SLEEVE, ì›ë³¸ ë¹„ì¤‘, 100% í™˜ì‚° ë¹„ì¤‘, DUR, ìµœì†Œ ë¹„ì¤‘, ìµœëŒ€ ë¹„ì¤‘, ìŠ¤ì½”ì–´ë§ ê¸°ëŒ€ìˆ˜ìµë¥ , GROUP)
        weight_display_df = weight_df[['SLEEVE', 'ì›ë³¸ ë¹„ì¤‘ (%)', '100% í™˜ì‚° ë¹„ì¤‘ (%)', 'DUR',
                                       'ìµœì†Œ ë¹„ì¤‘ (%)', 'ìµœëŒ€ ë¹„ì¤‘ (%)', 'ìŠ¤ì½”ì–´ë§ ê¸°ëŒ€ìˆ˜ìµë¥  (%)', 'GROUP']].copy()
    else:
        # ìµœì¢… í…Œì´ë¸” (EXPECTED_Rì´ ì—†ëŠ” ê²½ìš°)
        weight_display_df = weight_df[['SLEEVE', 'ì›ë³¸ ë¹„ì¤‘ (%)', '100% í™˜ì‚° ë¹„ì¤‘ (%)', 'DUR',
                                       'ìµœì†Œ ë¹„ì¤‘ (%)', 'ìµœëŒ€ ë¹„ì¤‘ (%)', 'GROUP']].copy()

    st.dataframe(weight_display_df, use_container_width=True, hide_index=True)

    # ê·¸ë£¹ë³„ ë¹„ì¤‘ ì œì•½ í‘œì‹œ ë° ë“€ë ˆì´ì…˜ ê³„ì‚°ì„ 2ì—´ë¡œ ë°°ì¹˜
    col1, col2 = st.columns(2)

    with col1:
        # ê·¸ë£¹ë³„ ë¹„ì¤‘ ì œì•½ í‘œì‹œ
        st.subheader("ê·¸ë£¹ë³„ ë¹„ì¤‘ ì œì•½")
        group_min_col = 'MIN_' + weight_col.replace('F', '')
        group_max_col = 'MAX_' + weight_col.replace('F', '')

        # ì»¬ëŸ¼ ì¡´ì¬ ì—¬ë¶€ í™•ì¸
        if group_min_col in Gr_MinMax_filtered.columns and group_max_col in Gr_MinMax_filtered.columns:
            # ê·¸ë£¹ë³„ MIN/MAX ë¹„ì¤‘ì„ % í˜•ì‹ìœ¼ë¡œ ë³€í™˜
            group_df = Gr_MinMax_filtered[['GROUP', group_min_col, group_max_col]].copy()
            group_df['ìµœì†Œ ë¹„ì¤‘ (%)'] = (group_df[group_min_col] * 100).round(2)
            group_df['ìµœëŒ€ ë¹„ì¤‘ (%)'] = (group_df[group_max_col] * 100).round(2)

            group_display_df = group_df[['GROUP', 'ìµœì†Œ ë¹„ì¤‘ (%)', 'ìµœëŒ€ ë¹„ì¤‘ (%)']].copy()
            st.dataframe(group_display_df, use_container_width=True, hide_index=True)
        else:
            st.warning(f"âš ï¸ ê·¸ë£¹ë³„ ë¹„ì¤‘ ì œì•½ ì»¬ëŸ¼({group_min_col}, {group_max_col})ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

    with col2:
        # ë“€ë ˆì´ì…˜ ê³„ì‚°
        st.subheader("í€ë“œ ë“€ë ˆì´ì…˜")
        dur_df = Current_filtered[['SLEEVE', 'DUR', weight_col]].copy()
        dur_df['ë¹„ì¤‘'] = dur_df[weight_col] / dur_df[weight_col].sum()
        portfolio_duration = (dur_df['DUR'] * dur_df['ë¹„ì¤‘']).sum()
        st.markdown(f'<p style="font-size: 14px;">í¬íŠ¸í´ë¦¬ì˜¤ ë“€ë ˆì´ì…˜: {portfolio_duration:.2f}</p>', unsafe_allow_html=True)

    # ìµœì í™” ì„¹ì…˜
    st.header("ìµœì í™” ì„¤ì •")

    # ì„¤ëª… í…ìŠ¤íŠ¸
    st.markdown("""
    - ìˆ˜ìµë¥ /ë³€ë™ì„±ì€ 3ê°œì›” ê¸°ê°„ ìˆ˜ìµë¥ /ë³€ë™ì„±ìœ¼ë¡œ ê³„ì‚°ë©ë‹ˆë‹¤.
    - ê°œë³„ Sleeveë³„ ë¹„ì¤‘ì€ ìœ„ì˜ 'Sleeveë³„ ì •ë³´' í…Œì´ë¸”ì˜ ìµœì†Œ, ìµœëŒ€ë¹„ì¤‘ì„ ì ìš©í•©ë‹ˆë‹¤.
    - ê·¸ë£¹ë¹„ì¤‘í•© ì œì•½ì€ 'ê·¸ë£¹ë³„ ë¹„ì¤‘ ì œì•½' í…Œì´ë¸”ì˜ ìµœì†Œ, ìµœëŒ€ ë¹„ì¤‘ì„ ì ìš©í•©ë‹ˆë‹¤.
    """)

    # 3ì—´ ë ˆì´ì•„ì›ƒìœ¼ë¡œ ì„¤ì • í‘œì‹œ
    col1, col2, col3 = st.columns(3)

    with col1:
        st.subheader("ê¸°ëŒ€ìˆ˜ìµë¥  ì„¤ì •")
        return_method = st.radio(
            "ê¸°ëŒ€ìˆ˜ìµë¥  ê³„ì‚° ë°©ë²•",
            ["ê³¼ê±°ìˆ˜ìµë¥ ", "ìœ„ì›íšŒ ìŠ¤ì½”ì–´ë§ ê²°ê³¼", "ëª¬í…Œì¹¼ë¡œ ì‹œë®¬ë ˆì´ì…˜"]
        )

        if return_method != "ìœ„ì›íšŒ ìŠ¤ì½”ì–´ë§ ê²°ê³¼":
            return_period = st.number_input(
                "ì°¸ì¡° ê¸°ê°„ (ê°œì›”)",
                min_value=1,
                value=36,
                step=1,
                help="ê³¼ê±°ìˆ˜ìµë¥ ì´ë‚˜ ëª¬í…Œì¹¼ë¡œ ì‹œë®¬ë ˆì´ì…˜ ë¶„ì„ì— ì‚¬ìš©í•  ê³¼ê±° ë°ì´í„° ê¸°ê°„ (ê°œì›” ìˆ˜). ì´ ê¸°ê°„ì˜ ë°ì´í„°ë¥¼ ì‚¬ìš©í•˜ì—¬ 3ê°œì›” ê¸°ê°„ ìˆ˜ìµë¥ ì„ ê³„ì‚°í•©ë‹ˆë‹¤."
            )
        else:
            # ìœ„ì›íšŒ ìŠ¤ì½”ì–´ë§ ê²°ê³¼ë¥¼ ì„ íƒí•œ ê²½ìš°ì—ë„ return_periodëŠ” í•„ìš” ì—†ì§€ë§Œ,
            # ì½”ë“œ ì¼ê´€ì„±ì„ ìœ„í•´ ê¸°ë³¸ê°’ ì„¤ì • (ì‹¤ì œë¡œëŠ” ì‚¬ìš©ë˜ì§€ ì•ŠìŒ)
            return_period = 3

    with col2:
        st.subheader("ë³€ë™ì„± ì„¤ì •")
        vol_period = st.number_input(
            "ë³€ë™ì„± ì°¸ì¡° ê¸°ê°„ (ê°œì›”)",
            min_value=1,
            value=36,
            step=1,
            help="ê³¼ê±°ë³€ë™ì„±ì„ ê³„ì‚°í•  ë•Œ ì°¸ì¡°í•  ê³¼ê±° ë°ì´í„° ê¸°ê°„ (ê°œì›” ìˆ˜). ì´ ê¸°ê°„ì˜ ë°ì´í„°ë¥¼ ì‚¬ìš©í•˜ì—¬ 3ê°œì›” ê¸°ê°„ ë³€ë™ì„±ì„ ê³„ì‚°í•©ë‹ˆë‹¤."
        )

    with col3:
        st.subheader("ì œì•½ì¡°ê±´ ì„¤ì •")
        dur_buffer = st.number_input(
            "DUR ì œì•½ ë²„í¼ (%)",
            min_value=0.0,
            max_value=100.0,
            value=20.0,
            step=1.0,
            help="í˜„ì¬ DURì— í”ŒëŸ¬ìŠ¤ ë§ˆì´ë„ˆìŠ¤ ê°€ëŠ¥í•œ í¼ì„¼íŠ¸"
        )

    # í…ìŠ¤íŠ¸ ë©”ì‹œì§€ëŠ” 3ì—´ ì•„ë˜ í–‰ì— í‘œì‹œ
    if return_method == "ìœ„ì›íšŒ ìŠ¤ì½”ì–´ë§ ê²°ê³¼":
        st.info("ìŠ¤ì½”ì–´ë§ ê¸°ì¤€ ê¸°ëŒ€ìˆ˜ìµë¥ ì€ 'Sleeveë³„ ì •ë³´' í…Œì´ë¸”ì— í‘œì‹œë˜ì–´ ìˆìŠµë‹ˆë‹¤.")

    # Risk-free Rate ì…ë ¥ (Max Sharpeì— í•„ìš”)
    st.subheader("Risk-free Rate")
    risk_free_rate = st.number_input(
        "Risk-free Rate (%)",
        value=0.0,
        step=0.1,
        help="Max Sharpe ìµœì í™”ì— ì‚¬ìš©ë©ë‹ˆë‹¤."
    )

    # ìµœì í™” ì‹¤í–‰ ë²„íŠ¼
    if st.button("Optimization", type="primary"):
        with st.spinner("ìµœì í™” ì§„í–‰ ì¤‘..."):
            # ìƒê´€ê´€ê³„ í–‰ë ¬ ê³„ì‚° (ëª¬í…Œì¹¼ë¡œ ì‹œë®¬ë ˆì´ì…˜ì— í•„ìš”)
            sleeves_list = Current_filtered['SLEEVE'].unique().tolist()
            corr_matrix = calculate_correlation_matrix(price_filtered, Current_filtered, sleeves_list)

            # ê¸°ëŒ€ìˆ˜ìµë¥  ê³„ì‚° (í•­ìƒ 3ê°œì›” ê¸°ê°„ ìˆ˜ìµë¥ ë¡œ ê³„ì‚°)
            calc_period = 3  # ê³ ì •ê°’
            if return_method == "ê³¼ê±°ìˆ˜ìµë¥ ":
                expected_returns = calculate_historical_returns(price_filtered, Current_filtered, return_period,
                                                                calc_period)
            elif return_method == "ìœ„ì›íšŒ ìŠ¤ì½”ì–´ë§ ê²°ê³¼":
                # Current ì‹œíŠ¸ì˜ EXPECTED_R ì¹¼ëŸ¼ì—ì„œ ì½ì–´ì˜¤ê¸° (3ê°œì›” ê¸°ê°„ ìˆ˜ìµë¥ )
                # ì—‘ì…€ì˜ % í˜•ì‹ ë°ì´í„°ëŠ” ì´ë¯¸ ì†Œìˆ˜ë¡œ ì½íˆë¯€ë¡œ, í¼ì„¼íŠ¸ë¡œ ë³€í™˜ í•„ìš”
                expected_returns = {}
                if 'EXPECTED_R' in Current_filtered.columns:
                    for sleeve in Current_filtered['SLEEVE'].unique():
                        sleeve_data = Current_filtered[Current_filtered['SLEEVE'] == sleeve]
                        expected_r_values = sleeve_data['EXPECTED_R'].dropna()
                        if len(expected_r_values) > 0:
                            # ì—‘ì…€ì—ì„œ ì½ì€ ê°’ì´ ì†Œìˆ˜(0.0123)ì´ë©´ í¼ì„¼íŠ¸(1.23)ë¡œ ë³€í™˜
                            val = expected_r_values.iloc[0]
                            # ê°’ì´ 1ë³´ë‹¤ ì‘ìœ¼ë©´ ì†Œìˆ˜ë¡œ ê°„ì£¼í•˜ê³  í¼ì„¼íŠ¸ë¡œ ë³€í™˜
                            expected_returns[sleeve] = val * 100 if val < 1.0 else val
                        else:
                            expected_returns[sleeve] = 0.0
                else:
                    st.error("Current ì‹œíŠ¸ì— EXPECTED_R ì¹¼ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤.")
                    expected_returns = {sleeve: 0.0 for sleeve in sleeves_list}
            else:  # ëª¬í…Œì¹¼ë¡œ ì‹œë®¬ë ˆì´ì…˜
                expected_returns = calculate_monte_carlo_returns(
                    price_filtered, Current_filtered, return_period,
                    corr_matrix, sleeves_list, calc_period
                )

            # ë³€ë™ì„± ê³„ì‚° (í•­ìƒ 3ê°œì›” ê¸°ê°„ ë³€ë™ì„±ìœ¼ë¡œ ê³„ì‚°)
            vol_calc_period = 3  # ê³ ì •ê°’
            volatilities = calculate_volatility(price_filtered, Current_filtered, vol_period, vol_calc_period)

            # ë³€ë™ì„± ë””ë²„ê¹… ì •ë³´
            if any(v == 0.0 for v in volatilities.values()):
                st.warning("âš ï¸ ì¼ë¶€ Sleeveì˜ ë³€ë™ì„±ì´ 0ì…ë‹ˆë‹¤. ë°ì´í„°ê°€ ì¶©ë¶„í•œì§€ í™•ì¸í•´ì£¼ì„¸ìš”.")
                with st.expander("ë³€ë™ì„± ê³„ì‚° ê²°ê³¼ í™•ì¸"):
                    for sleeve, vol in volatilities.items():
                        st.write(f"{sleeve}: {vol:.4f}%")

            # ì„¸ ê°€ì§€ ëª©ì í•¨ìˆ˜ ëª¨ë‘ ì‹¤í–‰
            objectives = ["Max Sharpe", "Min Risk", "Risk Parity"]
            results = {}

            for obj in objectives:
                optimal_weights_raw, optimal_weights_normalized, portfolio_return, portfolio_vol, optimal_duration, weight_changes = optimize_portfolio(
                    Current_filtered, Gr_MinMax_filtered, expected_returns, volatilities,
                    corr_matrix, weight_col, min_col, max_col, obj,
                    risk_free_rate if obj == "Max Sharpe" else 0.0,
                    dur_buffer, portfolio_duration, return_period
                )

                # ìƒ¤í”„ ë¹„ìœ¨ ê³„ì‚°
                sharpe_ratio = (portfolio_return - risk_free_rate) / portfolio_vol if portfolio_vol > 0 else 0

                results[obj] = {
                    'optimal_weights': optimal_weights_raw,
                    'optimal_weights_normalized': optimal_weights_normalized,
                    'portfolio_return': portfolio_return,
                    'portfolio_vol': portfolio_vol,
                    'optimal_duration': optimal_duration,
                    'weight_changes': weight_changes,
                    'sharpe_ratio': sharpe_ratio
                }

            # ê²°ê³¼ ì €ì¥
            st.session_state.optimization_results = results
            st.session_state.expected_returns = expected_returns
            st.session_state.volatilities = volatilities
            st.session_state.risk_free_rate = risk_free_rate

    # ìµœì í™” ê²°ê³¼ í‘œì‹œ
    if 'optimization_results' in st.session_state:
        st.header("ğŸ“Š ìµœì í™” ê²°ê³¼")

        results = st.session_state.optimization_results
        current_weights_dict = Current_filtered.set_index('SLEEVE')[weight_col].to_dict()
        total_current = sum(current_weights_dict.values())

        # í†µí•© ê²°ê³¼ í…Œì´ë¸” ìƒì„±
        comparison_data = []
        sleeves = Current_filtered['SLEEVE'].unique()

        for sleeve in sleeves:
            current_w = current_weights_dict.get(sleeve, 0)

            row_data = {
                'SLEEVE': sleeve,
                'í˜„ì¬ ë¹„ì¤‘ (%)': f"{current_w * 100:.2f}%",
                'Max Sharpe ë¹„ì¤‘ (%)': f"{results['Max Sharpe']['optimal_weights'].get(sleeve, 0) * 100:.2f}%",
                'Min Risk ë¹„ì¤‘ (%)': f"{results['Min Risk']['optimal_weights'].get(sleeve, 0) * 100:.2f}%",
                'Risk Parity ë¹„ì¤‘ (%)': f"{results['Risk Parity']['optimal_weights'].get(sleeve, 0) * 100:.2f}%",
            }

            # ê° ëª©ì í•¨ìˆ˜ë³„ ë³€í™”ëŸ‰
            row_data['Max Sharpe ë³€í™” (%)'] = f"{results['Max Sharpe']['weight_changes'].get(sleeve, 0) * 100:+.2f}%"
            row_data['Min Risk ë³€í™” (%)'] = f"{results['Min Risk']['weight_changes'].get(sleeve, 0) * 100:+.2f}%"
            row_data['Risk Parity ë³€í™” (%)'] = f"{results['Risk Parity']['weight_changes'].get(sleeve, 0) * 100:+.2f}%"

            comparison_data.append(row_data)

        comparison_df = pd.DataFrame(comparison_data)

        # í†µí•© ê²°ê³¼ í…Œì´ë¸” í‘œì‹œ (CSV ë‹¤ìš´ë¡œë“œ ë²„íŠ¼ í¬í•¨)
        col_title, col_csv = st.columns([10, 1])
        with col_title:
            st.subheader("ë¹„ì¤‘ ë¹„êµ (ì„¸ ê°€ì§€ ëª©ì í•¨ìˆ˜)")
        with col_csv:
            # í•œê¸€ ì¸ì½”ë”© ë¬¸ì œ í•´ê²°: UTF-8 BOMìœ¼ë¡œ ì¸ì½”ë”©
            csv = comparison_df.to_csv(index=False, encoding='utf-8-sig')
            csv_bytes = csv.encode('utf-8-sig')

            # íŒŒì¼ëª… ìƒì„±: ìœ„ì›íšŒ_ìµœì í™”ê²°ê³¼_530810_yymmdd.csv
            latest_date = st.session_state.get('latest_date', pd.Timestamp.today())
            date_str = latest_date.strftime('%y%m%d')
            fund_type = st.session_state.fund_selected
            file_name = f"ìœ„ì›íšŒ_ìµœì í™”ê²°ê³¼_{fund_type}_{date_str}.csv"

            st.download_button(
                label="CSV",
                data=csv_bytes,
                file_name=file_name,
                mime="text/csv;charset=utf-8",
                key="download_comparison_csv"
            )
        st.dataframe(comparison_df, use_container_width=True, hide_index=True)

        # ê° ëª©ì í•¨ìˆ˜ë³„ í¬íŠ¸í´ë¦¬ì˜¤ ì§€í‘œ í‘œì‹œ (í–‰ê³¼ ì—´ ì „ì¹˜)
        st.subheader("ëª©ì í•¨ìˆ˜ë³„ í¬íŠ¸í´ë¦¬ì˜¤ ì§€í‘œ")
        metrics_data = {
            'ê¸°ëŒ€ìˆ˜ìµë¥  (%)': [
                f"{results['Max Sharpe']['portfolio_return']:.2f}",
                f"{results['Min Risk']['portfolio_return']:.2f}",
                f"{results['Risk Parity']['portfolio_return']:.2f}"
            ],
            'ê¸°ëŒ€ë³€ë™ì„± (%)': [
                f"{results['Max Sharpe']['portfolio_vol']:.2f}",
                f"{results['Min Risk']['portfolio_vol']:.2f}",
                f"{results['Risk Parity']['portfolio_vol']:.2f}"
            ],
            'ë“€ë ˆì´ì…˜': [
                f"{results['Max Sharpe']['optimal_duration']:.2f}",
                f"{results['Min Risk']['optimal_duration']:.2f}",
                f"{results['Risk Parity']['optimal_duration']:.2f}"
            ],
            'ìƒ¤í”„ ë¹„ìœ¨': [
                f"{results['Max Sharpe']['sharpe_ratio']:.2f}",
                "-",
                "-"
            ]
        }

        metrics_df = pd.DataFrame(metrics_data, index=["Max Sharpe", "Min Risk", "Risk Parity"])
        metrics_df = metrics_df.T  # í–‰ê³¼ ì—´ ì „ì¹˜
        st.dataframe(metrics_df, use_container_width=True, hide_index=False)

else:
    st.info("ì‚¬ì´ë“œë°”ì—ì„œ ì—‘ì…€ íŒŒì¼ì„ ì—…ë¡œë“œí•˜ê³  í€ë“œ(530810 or 530950)ë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”.")

